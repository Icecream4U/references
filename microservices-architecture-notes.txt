##1##
-----
Microservices are ideal for big systems
Microservice architecture is goal-oriented
Microservices are focused on replaceability

At the end of our three-day meeting, one of us called out a theme—that year it had been clear that many of the problems people were facing in the wild were related to building systems that were too big. “How can I rebuild a part of this,” “best ways to implement Strangler,” etc.
Turning that on its head, the problem became “how can we build systems that are replaceable over being maintainable?”
We used the term micro apps, I seem to remember.
—James Lewis

Microservices are small, autonomous services that work together.
—Sam Newman, Thoughtworks

Loosely coupled service-oriented architecture with bounded contexts.
—Adrian Cockcroft, Battery Ventures

A microservice is an independently deployable component of bounded scope that supports interoperability through message-based communication.
Microservice architecture is a style of engineering highly automated, evolvable software systems made up of capability-aligned microservices.
-Martin Fowler

microservice applications share some important characteristics:
• Small in size
• Messaging enabled
• Bounded by contexts
• Autonomously developed
• Independently deployable
• Decentralized
• Built and released with automated processes

Speed and Safety at Scale and in Harmony.
—The Microservices Way

* Speed of Change: Most organizations have the platforms, tools, and infrastructure in place to implement thousands of application releases within a single day. But they don’t. In fact, most teams are happy if they can manage a release in a week. Why is that? The answer of course is that the real deterrent to release speed is the fragility of the software they’ve produced.
* Safety of Change: Every change is potentially a breaking change and a system optimized purely for speed is only realistic if the cost of breaking the system is near zero. Most development environments are optimized for release speed, enabling the software developer to make multiple changes in as short a time as possible. On the other hand, most production environments are optimized for safety, restricting the rate of change to those releases that carry the minimum risk of damage.
* At Scale: microservices style is rooted in the idea of solving the problems that arise when software gets too big. To build at scale means to build software that can continue to work when demand grows beyond our initial expectations. Systems that can work at scale don’t break when under pressure; instead they incorporate built-in mechanisms to increase capacity in a safe way.
* In Harmony: microservice architecture is not limited to a simple series of decisions regarding speed and safety of change. The microservices domain is actually fairly complex and will require you to understand a wide breadth of concepts that have a great depth of impact.

-----
##2##
-----
The greater the cohesion of individual modules in the system, the lower the coupling between modules will be.
—Larry Constantine and Edward Yourdon, authors of Structured Design: Funda‐ mentals of a Discipline of Computer Program and Systems Design

The key in making great and growable systems is much more to design how its modules communicate rather than what their internal properties and behaviors should be.
—Alan Kay, 1998 email to the Squeak-dev list (http://lists.squeakfoundation.org/pipermail/squeak-dev/1998-October/017019.html)

Dealing with complex systems requires a careful approach based on influence versus control

-----
##3##
-----
The very first step of a service design process is to design the process itself.
—Marc Stickdorn, author of This is Service Design Thinking

Bad designers make assumptions about how a system works, apply changes in the hope that it will produce desired behavior, and call it a day. Good designers make small system changes, assess the impact of those changes, and continually prod the system behavior toward a desired outcome. But a good design process is predicated on your ability to get feedback from the system you are designing. This is actually much more difficult than it sounds—the impact of a change to one small part of the system may result in a ripple of changes that impact other parts of your system with low visibility.
Gain essential visibility into our system by identifying a few key measurements that give us the most valuable information about system behavior. In organizational design, this type of metric is known as a key performance indicator (KPI). The challenge for the microservice designer is to identify the right ones.
The risk of making poor decisions is that we steer the system in a direction that increases our “technical debt” (i.e., the future cost of addressing a technical defi‐ ciency). If we go too far along the wrong path we risk producing a system that becomes too expensive to change, so we give up.

The classic microservices example of this is the cautionary tale of the “monolith.” A team creates an initial release of an application when the feature set is small and the componentry has low complexity. Over time, the feature set grows and the complex‐ ity of the deployed application grows, making change ever more difficult. At this point, the team agrees that the application needs to be redesigned and modularized to improve its changeability. But the redesign work is continually deferred because the cost of that work is too high and difficult to justify.
At the other end of the scale is a system that is so overdesigned and overengineered for future flexibility that it becomes impractical. An incredibly complex, adaptable system that is built for massive amounts of change that never seems to happen.
So, in order to design a microservice system that is dynamic you’ll need to identify the right KPIs, be able to interpret the data, and make small, cheap changes to the system that can guide you back on the right course. This is only possible if the right organization, culture, processes, and system architecture are in place to make it cheap and easy to do so.

-----
##4##
-----
Goals for the Microservices Way
From our research, we’ve been able to distill four specific goals that lead to practices that aid both safety and speed of change.
These goals aren’t unique to microservice architecture, but they are useful in shaping your journey.
Here are the four goals to consider:
1. Reduce Cost: Will this reduce overall cost of designing, implementing, and maintaining IT services?
2. Increase Release Speed: Will this increase the speed at which my team can get from idea to deployment of services?
3. Improve Resilience: Will this improve the resilience of our service network?
4. Enable Visibility: Does this help me better see what is going on in my service network
Trade-off for all these four.

Operating Principles
Along with a set of goals for a microservice approach, it is important to have a set of principles. Unlike goals, which are general, principles offer more concrete guidance on how to act in order to achieve those goals. Principles are not rules—they don’t set out required elements. Instead, they offer examples on how to act in identifiable situa‐ tions. Principles can also be used to inform best practices. Many of the organizations we looked at when doing research have their own set of principles within their company.

Netflix operating principles:
- Antifragility: The point of antifragility is that you always want a bit of stress in your system to make it stronger. Simian Army.
- Immutability: assert that auto- scaled groups of service instances are stateless and identical, which enables Netflix’s system to “scale horizontally.” The Chaos Monkey, removes instances regularly to enforce the immutable stateless service principle.
Another related technique is the use of “Red/Black pushes”. Although each released component is immutable, a new version of the service is introduced alongside the old version, on new instances, then traffic is redirected from old to new. After waiting to be sure all is well, the old instances are terminated.
- Separation of Concerns: The Netflix microservice architecture arises because of separation of concerns (SoC) in the engineering team organization. Each team owns a group of services. They own building, operating, and evolving those services, and present a stable agreed interface and service level agreement to the consumers of those services. Invoking Conway’s law, an organization structured with independent self- contained cells of engineers will naturally build what is now called a microservice architecture.

Unix
A succinct set of software architecture principles appears in the foreword for the 1978 edition of Bell Labs’ “UNIX Timesharing System” documentation. The four points (listed next) were offered as a set of “maxims that have gained currency among the builders and users of the Unix system.”
Here is the list Douglas McIrloy and his colleagues called out:
1. Make each program do one thing well. To do a new job, build afresh rather than complicate old programs by adding new features.
2. Expect the output of every program to become the input to another, as yet unknown, program. Don’t clutter output with extraneous information. Avoid stringently columnar or binary input formats. Don’t insist on interactive input.
3. Design and build software, even operating systems, to be tried early, ideally within weeks. Don’t hesitate to throw away the clumsy parts and rebuild them.
4. Use tools in preference to unskilled help to lighten a programming task, even if you have to detour to build the tools and expect to throw some of them out after you’ve finished using them.
One of the interesting things about these four principles is that they offer general guidance on how to think about writing software. Phrases like “do one thing well” and “build software ... to be tried early” can lead developers to adopt what is known in the Unix world as “The Rule of Parsimony” when writing code (“only write a big program when nothing else will do”). This along with other Unix rules provides developers with a set of guidelines for which programming languages or libraries to use. These principles are also meant to shape developers’ thinking.

Suggested principles
There is no one set of principles that matches every company. Each organization needs to create a set that works for their company.
- Do one thing well
- Build afresh (something similar to Netflix immutability principle)
- Expect output to become input
- Don’t insist on interactive input: In the Unix world, there is a desire to create scripts that tie a number of command-line tools together to create a “solution.” This means humans don’t need to be engaged every step of the way the scripts handle both the input and the output on their own. Reducing the need for human interaction increases the likelihood that the component can be used in unexpected ways.
- Try early: The earlier you release (even when that release is to a test environment), the earlier you get feedback and the quicker you can improve.
- Don’t hesitate to throw it away: However, when you adopt the “try early” principle, throwing away the early attempts is easier.
It is also important to consider this “throw it away” principle for components that have been running in production for a long time. Over time, components that did an important job may no longer be needed. You may have applied the “build afresh” principle and replaced this component with one that does the job better. It may be the case that the “one thing” that component does is simply no longer needed. The important thing is to be willing to throw away a component when it no longer serves its intended purpose.
- Toolmaking: One of the important elements in the developmental history of humans was the ability to create tools. These tools were created in order to reach a goal. In some cases, you may need to divert from building your solution and spend some time building tools to help you build that solution.

Microservices concerns
- Shared capabilities (platform services that all teams use):
  - Hardware services
  - Code management, testing, and deployment
  - Data stores
  - Service Orchestration
  - Security and identity
  - Architectural policy
- Local capabilities (selected and maintained at the team or group level to help teams become more self-sufficient):
  - General tooling
  - Runtime configuration (Twitter's Decider | Facebook's Gatekeeper)
  - Service discovery (Zookeeper | etcd | Consul)
  - Request routing (Zuul | Netty | Finagle)
  - System observability (Zipkin | Hystrix)
- Culture (The code your team produces is the result of the culture)
  - Communication
  - Team alignment (The Mythical Man Month | 2-pizza team | squad&tribe)
  - Fostering innovation (setting boundaries that prevent teams from taking actions that threaten the health and welfare of the company and allowing teams to act on their own within these safe boundaries)


-------------------------------------------------
Microservices in practice
##5##
To understand the DDD approach, it is important to remember that any software system is a model of a reality it is not the reality itself. For instance, when we log in to online banking and are looking at our checking account, we are not looking at the actual checking account. We’re just looking at a representation, a model, that gives us information about the checking account such as balance and past transactions. It’s likely that the screen our bank teller sees when looking at our account has different information because it’s another model of our account.
Evans notes that most large systems don’t actually have a single model. The overall model of a large system is actually comprised of many smaller models that are intermingled with each other. These smaller models are organic representations of relevant business contexts, they make sense in their context and when used within the context they are intuitive for a person who is the subject matter expert of the context.

bounded contexts represent autonomous business domains (i.e., distinct business capabilities), and therefore are the appropri‐ ate starting point for identifying the dividing lines for microservices. If we use the DDD and bounded contexts approaches, the chances of two microservices needing to share a model and the corresponding data space, or ending up having tight coupling, are much lower. Avoiding data sharing improves our ability to treat each microservice as an independently deployable unit. And independent deployability is how we can increase our speed while still maintaining safety within the overall system.

Bounded context should be as big as it needs to be in order to fully express its complete ubiquitous language.
—Vaughn Vernon, author of Implementing Domain–Driven Design

From a purely technical perspective, the smaller the microservice the easier it can be developed quicker (Agile), iterated on quicker (Lean), and deployed more frequently (Continuous Delivery). But on the modeling side, it is important to avoid creating services that are “too small.” According to Vernon, we cannot arbitrarily reduce the size of a bounded context because its optimal size is determined by the business con‐ text (model). Our technical need for the size of a service can sometimes be different (smaller) from what DDD modeling can facilitate.

Just as we need to achieve a high level of separation, independence, and modu‐ larity of our code we need to make sure that our APIs, the component interfaces, are also loosely coupled. Otherwise, we won’t be able to deploy two microservices inde‐ pendently, which is one of our primary goals in order to balance speed and safety.

The first step in breaking the data-centric habit is to rethink our system designs. We need to stop designing systems as a collection of data services and instead use busi‐ ness capabilities as the design element, or as Sam Newman notes in his book:
You should be thinking not in terms of data that is shared, but about the capabilities those contexts provide [...]. I have seen too often that thinking about data leads to ane‐ mic, CRUD-based (create, read, update, delete) services. So ask first “What does this context do?” and then “So what data does it need to do that?”
—Sam Newman, author of Building Microservices
It turns out that capabilities-centric design is more suitable for microservices than a more traditional, data-centric design.

Thinking in terms of capabilities rather than data is a very powerful technique for API design, in general. It usually results in a more use-case-oriented interface (instead of an SQL-like data-object interface). A capabilities-centric API design is usually a good approach, but in the case of microservices it is not just a smart design technique, it’s a powerful way of avoiding tight coupling.

Much like bounded context analysis, capabilities-oriented design is a crucial techni‐ que but not sufficient to ensure independent deployability for all use cases. We cannot always encapsulate shared data inside a microservice and call it a day. For example, a common use case that cannot be solved with encapsulated capabilities is that of reporting. Any business application requires a certain level of reporting. And reporting often spans across multiple models, bounded contexts, and capabilities. Should reporting-oriented microservices be allowed to share tables with other microservices? The obvious answer is no, because that would immediately create severe tight coupling of services all around the system, and at the very least undermine (if not completely kill) independent deployability.

Instead of storing struc‐ tures that model the state of our world, we can store events that lead to the current state of our world. This modeling approach is called event sourcing. 
Event sourcing is all about storing facts and any time you have “state” (structural mod‐ els)—they are first-level derivative off of your facts. And they are transient.
—Greg Young, Code on the Beach, 2014

the roots and inspiration for event sourcing go way beyond microservi‐ ces, the Internet itself, or even computers—all the way back to financial accounting and the paper-and-pen ledgers that contain a list of transactions, and never just the end value (“state”) of a balance. Think of your bank account: there’s a balance amount for your checking and savings accounts, but those are not first-class values that banks store in their databases. The account balance is always a derivative value; it’s a func‐ tion. More specifically, the balance is the sum of all transactions from the day you opened your account.

This is another crucial property of event sourcing: much like in life, we can never “go back” in time and “change” the past, we can only do something in the present to compensate for the mistakes of the past. In event sourcing, data is immutable—we always issue a new command/event to compensate rather than update a state of an entity, as we would do in a CRUD style.

When event sourcing is introduced to developers, the immediate concern is usually performance. If any state value is a function of events, we may assume that every access to the value would require recalculation of the current state from the source events. Obviously that would be extremely slow and generally unacceptable. Fortunately, in event sourcing, we can avoid such expensive operations by using a so-called rolling snapshot—a projection of the entity state at a given point in time. Depending on the event source implementation, it is common to snapshot intermediary values at various time points. For instance, you may precalculate your bank account balance on the last day of every month, so that if you need the balance on January 15, 2016 you will already have it on December 31, 2015 and will just need to calculate the projec‐ tion for two weeks, instead of the entire life of the bank account. 

If you enjoy noticing patterns in seemingly unrelated things the way we do, we urge you to take another look at the two diagrams. You may notice how every entity in the structural model is a “snowflake” (i.e., it has a unique “shape,” in terms of properties and relationships, and was attentively crafted to represent differing real-life con‐ cepts). In contrast, events in an event store all look the same from the outside. This is a very similar view to another technology closely related to microservices: containers. Indeed, for the container host (e.g., a Docker host), all containers look alike—the host doesn’t “care” what is inside a container, it knows how to manage the lifecycle of a container independent of the contents of the container. In contrast, custom-installed enterprise applications have all kinds of peculiar “shapes” and environmental depen‐ dencies that the host must ensure exist (e.g., shared libraries the application expects). The “indifference to shape and contents” approach seems to be a trend in modern technologies, as we can see the same pattern in SQL versus NoSQL storage. It is very reminiscent, in its tendency to show up under multiple contexts, of the “batch-size reduction” trend we noticed earlier while looking at different modern methodologies across multiple disciplines (e.g., project management, product development, opera‐ tions, and architecture). We love this—when the same pattern emerges in multiple places, we can use our understanding of the pattern to identify or predict “next big thing.”

Command query responsibility segregation is a design pattern that states that we can (and sometimes should) separate data-update versus data-querying capabilities into separate models. It tracks its ancestry back to a principle called command–query sep‐ aration (CQS), which was introduced by Bertrand Meyer in his book Object-Oriented Software Construction (Prentice-Hall, 1997). Meyer argued that data-altering operations should be in different methods, separated from methods performing read-only operations. CQRS takes this concept a large step further, instructing us to use entirely different models for updates versus queries.

Since reports usually need to aggregate and contrast data generated in different parts of a large system, they often need to span multiple subsystems and bounded contexts and almost always require access to data from multiple contexts. But it is only so if we assume we have a single model for any entity, where we both query and update the entity. If we instead use CQRS, the need to access data across multiple contexts (and related problems) can be eliminated. With CQRS, the Shipment Management micro‐ service can “own” and encapsulate any updates related to package delivery, just notifying other contexts about events occurring. By subscribing to notifications of these events, a reporting service such as Shipment Tracking can build completely inde‐ pendent, query-optimized model(s) that don’t need to be shared with any other service.

The big win with using event sourcing and CQRS is that they allow us to design very granular, loosely coupled components. With bounded contexts our boundaries have to align with business capabilities and subdomain boundaries. With event sourcing, we can literally create microservices so tiny that they just manage one type of event or run a single report. Targeted use of event sourcing and CQRS can take us to the next level of autonomous granularity in microservice architecture. As such, they play a crucial role in the architectural style.

Be careful not to abuse/overuse event sourcing and CQRS. You should only use event sourcing and CQRS when necessary, since they will complicate your implementation. Event sourcing and CQRS are not an “architecture” for your entire system, rather they are a powerful toolset to be used sparingly. There are still many use cases in which the conventional, CRUD-based model is much simpler and should be preferred.

Letting microservices directly interact with message brokers (such as RabbitMQ, etc.) is rarely a good idea. If two microservices are directly communicating via a message-queue channel, they are sharing a data space (the channel) and we have already talked, at length, about the evils of two microservices sharing a data space. Instead, what we can do is encapsulate message-passing behind an independent microservice that can provide message-passing capability, in a loosely coupled way, to all interested microservices.
The message-passing workflow we are most interested in, in the context of microservice architecture, is a simple publish/subscribe workflow. How do we express it as an HTTP API/microservice in a standard way?


Centralized data storage is operationally convenient: it allows dedicated, specialized teams (DBAs, sysadmins) to maintain and fine-tune these complex systems, obscur‐ ing the complexity from the developers.
In contrast, microservices favor embedding of all their dependencies, in order to ach‐ ieve independent deployability. In such a scenario, every microservice manages and embeds its database, key-value store, search index, queue, etc. Then moving this microservice anywhere becomes trivial.
The postulate of wholesale embedding of (data storage) dependencies looks beautiful on the surface, but in practice it is extremely wasteful for all but the simplest use cases. It is obvious that you will have a very hard time embedding entire Cassandra, Oracle, or ElasticSearch clusters in each and every microservice you develop. Espe‐ cially if you are far down the microservices journey and possibly have hundreds of microservices. This is just not doable. Neither is it necessary.
In reality, a microservice doesn’t have to carry along every single dependency (such as a data storage system) in order to be mobile and freely move across the data centers. The trick to microservice mobility is not packing everything but instead ensuring that the deployment destination provides heavy assets, such as database clusters, in a usable and auto-discoverable form at every destination where a micro‐ service may be deployed. Microservices should be written so that they can quickly discover those assets upon deployment and start using them. Data sharing between microservices is still the ultimate no-no. Sharing data creates tight coupling between microservices, which kills their mobility. However, sharing a database cluster installation is absolutely OK, given that each microservice only accesses isolated, namespaced portions of it.
The most important question we need to ask, when deciding on embedding dependencies versus “expecting” traits in an environment, is will our decision increase or decrease mobility? Our goal is to maximize deployment mobility of a microservice, which may mean different things in different contexts

##6##

We already noted that the IPs a microservice is available at are ever-changing, but what about the port? You might assume that we can assign fixed ports to individual microservices, in essence saying, “our account management microservice always launches on port 5555.” But this would not be a good idea. Generally speaking, many different teams will need to independently launch microservices on, likely, a shared pool of hosts. If we assumed that a specific microservice always launches on a specific port of a host, we would require a high level of cross-team coordination to ensure that multiple teams don’t accidentally claim the same port. But one of the main moti‐ vations of using a microservice architecture is eliminating the need for costly cross- team coordination. Such coordination is untenable, in general. It is also unnecessary since there are better ways to achieve the same goal.
This is where service discovery enters the microservices scene. We need some system that will keep an eye on all services at all times and keep track of which service is deployed on which IP/port combination at any given time, so that the clients of microservices can be seamlessly routed accordingly.
We have tools such as Etcd from CoreOs and Consul by HashiCorp. They are “low-level” tools providing a high degree of control and visibility to an architect. On the other side of the spectrum are tools that provide “container-scheduling” capabilities, alongside the service discovery. Kubernetes from Google is probably the most well-known in this category, Docker Swarm being another. With container-scheduling solutions, we get a high degree of automation and abstraction. In this scenario, instead of deciding which container is launched on which servers, we just tell the system how much of the host pool’s resources should be devoted to a particular service and Kubernetes or Swarm takes care of balancing/rebalancing containers on the hosts, based on these criteria. Another important technology utilizing containers is Mesosphere. Mesosphere is even more abstracted than Kubernetes or Swarm, currently marketed as “a data center operating system” that allows a higher degree of automation, without having to worry about the many nodes deployed, and operating the entire server cluster almost as if it were a single superserver.

The Need for an API Gateway
Modern API gateways provide an additional, critical feature required by microservices: trans‐ formation and orchestration. Last but not least, in most mature implementations, API gateways cooperate with service discovery tools to route requests from the clients of microservices.
Sometimes, certain microservices are deemed “internal” and excluded from the secu‐ rity provided by an API Gateway, as we assume that they can never be reached by external clients. This is dangerous since the assumption may, over time, become inva‐ lid. It’s better to always secure any API/microservice access with an API gateway. In most cases the negligible overhead of introducing an API gateway in between service calls is well worth the benefits.
Orchestration: Fortunately, since the “chattiness” problem in the APIs is not new, mature API gate‐ ways are perfectly equipped to deal with the problem. A capable API gateway will allow you to declaratively, through configuration, create API interfaces that can orchestrate backend microservices and “hide” their granularity behind a much more developer-friendly interface and eliminate chattiness.
Routing: An API gateway can inter‐ face with either HTTP or DNS interfaces of a service discovery system and route an API client to the correct service when an external URI associated with the microser‐ vice is requested. You can also use a load balancer or smart-reverse proxy to achieve the same goal, but since we already use API gateways to secure routes to microservi‐ ces, it makes a lot of sense for the routing requirement to also be implemented on the gateway.

Monitoring and Alerting
While microservice architecture delivers significant benefits, it is also a system with a lot more moving parts than the alternative—monolith. As such, when implementing a microservice architecture, it becomes very important to have extensive system-wide monitoring and to avoid cascading failures.
Just because a container instance for a microservice is up and running doesn’t always mean the microservice itself is healthy. We may want to additionally check that the microservice is responding on a specific port or a specific URL, possibly even checking that the health ping returns predetermined response data.
We can also configure “push"-oriented health checks, where the microservice itself is responsible for periodically checking. This alternative workflow is very valuable for scheduled services that must run on predetermined schedules. It is often hard to verify that scheduled jobs do run as expected, but the “push”-based health-check workflow can give us exactly what we need.

##7##



-----------
## Links ##
-----------
Links linked for shis book: https://github.com/apiacademy/MSABook

Four principles of low risk sofware releases: https://www.informit.com/articles/article.aspx?p=1833567

“If it moves graph it. If it matters, alert on it”.: https://www.slideshare.net/jallspaw/dev-and-ops-collaboration-and-awareness-at-etsy-and-flickr/32-Maintainability_Versus_MTTR_Optimized_MTBF

https://www.slideshare.net/adrianco
https://slides.yowconference.com/yow2013/Cockcroft-CloudNativeArchitectureNetflix.pdf
https://www.slideshare.net/adriancockcroft

The Netflix Simian Army: https://netflixtechblog.com/the-netflix-simian-army-16e57fbab116

State of the art in microservices (2014): https://www.slideshare.net/adriancockcroft/dockercon-state-of-the-art-in-microservices

Twitter's Decider configuration tool: https://www.infoq.com/articles/twitter-infrastructure/
Facebook's Gatekeeper: http://sigops.org/s/conferences/sosp/2015/current/2015-Monterey/printable/008-tang.pdf

Circuit Braker: https://martinfowler.com/bliki/CircuitBreaker.html

Why we do it the way we do it: https://www.slideshare.net/dev2ops/you-cant-change-culture-but-you-can-change-behavior-and-behavior-becomes-culture

Netflix context, not control: https://www.linkedin.com/pulse/netflixs-context-control-how-does-work-steve-urban

Continuous delivery: https://martinfowler.com/bliki/ContinuousDelivery.html

CQRS & Event sourcing by Greg Young: https://www.youtube.com/watch?v=JHGkaShoyNs

Original Sagas paper by Hector Molina (1987): ftp://ftp.cs.princeton.edu/reports/1987/070.pdf
Simple example of Saga (2012): https://web.archive.org/web/20160329160540/http://vasters.com/clemensv/2012/09/01/Sagas.aspx

Microservices by J.Lewis and M.Fowler: https://martinfowler.com/articles/microservices.html

Docker for microservices survival guide: https://www.freshblurbs.com/blog/2016/02/27/docker-microservices-survival-guide.html

---------
## Cit ##
---------
Gall's Law: A complex system that works is invariably found to have evolved from a simple system that worked (which bring us to "Monolith first")

You build it, you run it.
—Werner Vogels, Amazon CTO
In small organizations, it is likely that the local capability elements will be the same for the entire company (e.g., the small startup is just a single team anyway). However, as the company grows, acquires new products, and expands into new technology and mar‐ ket spaces, forcing everyone to continue to use the same developer tools, routing implementations, etc., does not scale well. At that point, it makes sense to allow product groups to start making those decisions for themselves.

Organizations which design systems ... are constrained to produce designs that are copies of the communication structures of these organizations.
—Mel Conway, author of “How Do Committees Invent?”

I have neither the place, the time, nor the desire, to micromanage or make technical decisions for [my team].
—Steve Urban, Netflix engineer

-----------
## Books ##
-----------
The End of Average by Todd Rose (Harper Collins, 2016). Rose has given a TEDx talk on the subject of averages and is a leading proponent of an interdisciplinary field called “The Science of the Individual”.

Structure in Fives by Henry Mintzberg (organizational designer)

Grooming, Gossip and the evolution of language by Robin Dunbar (https://www.hup.harvard.edu/catalog.php?isbn=9780674363366)

RESTful Web APIs by Mike Amundsen, Sam Ruby, Leonard Richardson

-----------
## Tools ##
-----------
Morgue (Etsy post mortem tracing) https://github.com/etsy/morgue

Aminator (Netflix AMI creation tool) https://netflixtechblog.com/ami-creation-with-aminator-98d627ca37b0

Asgard (Web-based cloud management and depoyment) https://netflixtechblog.com/asgard-web-based-cloud-management-and-deployment-2c9fc4e4d3a1

etcd (key-value store for distributed systems) https://etcd.io/
